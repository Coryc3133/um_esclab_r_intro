---
title: "Introduction to R"
author: "Jessica Kosie"
date: "9/17/2018"
output: 
  html_document:
    toc: true
    toc_float: true
---

# Goals 

By the end of this tutorial, you will know:

+ Basic `R` usage (using `R` as a calculator, creating variables, indexing vectors)
+ How to read in and examine data
+ How to get values out of the rows and columns in your data
+ What a pipe is and how to use pipes to chain together `tidyverse` verbs
+ Begin understanding tidyverse "verbs" (we'll continue on Thursday)

The best way to do this tutorial is to walk through it slowly, executing each line and trying to understand what it does. You can execute a single line by placing your cursor somewhere in that line and hitting CMD+enter (again on a mac) and execute a whole chunk at a time by hitting CMD+option+C (on a mac). 

# 1. Basic R Use

R can simply be used as a calculator.

```{r}
# Basic arithmetic
2+3
2*3
10/2
4^2

# Follows order of operations (PEMDAS)
(2^3)+4*(5/3)
```

These values aren't stored anywhere though. 

To keep them in memory, we need to assign them to a variable. 

```{r}
# Create a variable called x, that is assigned the number 8. 
x <- 8 
x = 8

# What value did I assign to x?
x

# What about y?
y

# Need to assign something to y!
y <- 2

y

# And we can do things with these variables:
x + y
x * y

z <- x * y

# Can use any name you want! But...object names must start with a letter, and can only contain letters, numbers, "_" and "." So, there are different options.

this_is_snake_case <- 8
thisIsCamelCase <- 8
some.people.use.periods <- 8
And_someTimes.People_doSTRANGEtHiNgS <- 8

# Can also assign a range of values
x <- 1:5 #x is now a vector of 1, 2, 3, 4, 5

# Note that x is no longer 8, it take on whatever the most recent assignment was

# We can also assign a vector of values this way
x <- c(2, 8, 1, 9)
```

Vectors are just 1-dimensional lists of numbers.

```{r}
# Let's get the numbers 1 thru 10 by ones 
1:10

# Sequence of numbers, 1 thru 10, by 2
seq(from = 1, to = 10, by = 2) #can say "from", "to", and "by=", but they're not necessary

```

> **Exercise 1a.** Create a variable called x that is assigned the number 8. Create a variable called y that is a sequence of numbers from 2 to 16, by 2. Add x and y. What happens? 

```{r}


```

> **Exercise 1b.** Create a variable called z that is a vector containing the numbers 5 and 10. Create a variable called q that is a sequence of numbers from 5 to 25, by 5. Multiply x and y. What happens? 

```{r}


```
## 2. Functions

`seq` that we used above is a **function**. Everything you typically want to do in statistical programming uses functions. Functions can take different **arguments**.

For example, `sqrt` is a function that can take one numeric argument. We are going to **apply** the function `sqrt` to the value 16.
```{r}
sqrt(16)

# I could have assigned 16 to a variable first:
x <- 16

# And then taken the square root of that variable:
sqrt(x)

```
The function `sqrt` can also take a vector as the argument.
```{r}
# Create a vector:
x <- 1:10

# Get the square root of every number in that vector:
sqrt(x)

```
Another good example is the function `mean`. `mean` takes one **argument**, a numeric vector. We are going to create a vector called `z` and **apply** this function to that vector.

```{r}
z <- 0:20
mean(z)

# Now, let's get the mean of this vector:
q <- c(2, 8, 6, NA, 4, 8)

q

mean(q)

# Is that the answer you'd expect? let's get some information about the function `mean`
?mean

# We need to add an additional argument to tell the function that we want to ignore NAs (the default for this argument is FALSE, that's why NAs weren't ignored above)
mean(q, na.rm = TRUE)
```

> **Exercise 2a.** R has a function called `rnorm` that will allow you to get a random sample of numbers drawn from a normal distribtuion. Get a sample of 5 numbers with a mean of 0 and a standard deviation of 0.5.  

```{r}
# Hint:
?rnorm


```

There are multiple ways to create arrays of number.

```{r}
# As before, we can get a sequence of numbers, 1 thru 10, by 2
s <- seq(1,10,2) #can say "by=" before the 2, but it's not necessary

# Sequence of 11 equally spaced numbers between 0 and 1
s2 <- seq(0,1,length.out=11) 

# Side note: what if I don't want these things in my environment any more?
rm(x)
rm(q)
rm(s)

# Remove everything
rm(list=ls())

# Can bind things together

x <- 1:10
y <- 11:20
z <- c(x,y) #combines them into one vector
z1 <- cbind(x,y) #combines them into two columns in a matrix
z2 <- rbind(x,y) #combines them into two rows in a matrix

```

Speaking of matrices: Creating and indexing matrices

```{r}
x <- matrix(c(11,12,13,21,22,23), byrow=TRUE,nrow=2) #put into a matrix by row
x1 <- matrix(c(11,12,13,21,22,23), byrow=FALSE,nrow=2) #put into a matrix by column

# Indexing matrices (getting the value that's in a particular row/column)

# x[r,c] would give you the element in row r, column c of the matrix

x[2,3] #gives you the element in row 2 column 3 of matrix x (defined above)
x[] #all rows, all columns - could have just typed x
x[1, ] #first row, all columns
x[ ,3] #all rows, third column
x[1,3] #first row, third column

y <- x[1,2] #assign the value in the 1st row 2nd column to a new variable
```

> **Exercise 2b.** Create a matrix with the following values:
row 1: 10, 26, 32
row 2: 4, 8, 16
row 3: 9, 12, 10

Save it to the variable my_matrix.

```{r}


```

> **Exercise 2c.** Use indexing (as described above) to pull out the value in row 1, column 3. What is this value? 

```{r}


```

> **Exercise 2d.** Next, using indexing to pull out the value 16. (Hint: which row and column is it in?) Save it to the variable z.

```{r}


```

> **Exercise 2e.** Finally, save column 2 to a variable called col_2 and add this to z.

```{r}



```

## 3. Generating random numbers.

```{r}

# Previously we used `rnorm`, `runif` is similar, but it draws from a uniform distribution.

runif(1) #generates 1 random number from a uniform distribution from 0 to 1 (as defaults)
runif(2, min=3, max=5) #generates 2 random numbers from a uniform distribution from 3-5

#can hit the up arrow and run this again and again - draw lots of samples of 2
#can hit the up arrow and change things:
#up arrow gives you this runif(2, min=3, max=5) if you haven't yet run the line, you can edit any of the values.

# Sample gives whole numbers
sample(1:10, 3) #without replacement
sample(1:10, 3, replace=TRUE) #keep running this you might get a couple #s that are the same
sample(1:10, 30, replace=TRUE) #more likely to get numbers that are the same since it's a bigger sample

# Note that we'll get different numbers, unless we all set the same seed before we run the function
set.seed(5678)
sample(1:10, 3)

# Can create a matrix of random numbers
x <- matrix(runif(100), ncol=2) #100 row, 2 column vector of random numbers from a uniform dist.

x <- rnorm(5) #5 numbers from a normal dist. w/ mean=0 SD=1

# Can set parameters of the normal distribution
x <- rnorm(1, mean=100, sd=15) #draw one number from normal dist. w/ mean=100, SD=15 (e.g., 1 IQ score)

# We can also round that number
round(x, 2)

```

> **Exercise 3a.** Set the seed to 8642 and create a matrix (with 10 rows and 20 columns) of 200 numbers randomly drawn from a normal distribution. Use the default mean and sd. Enter the numbers by row. Save this matrix to a variable (you can call it anything you'd like).  

```{r}


```

> **Exercise 3b.** Use indexing to get the value in row 2, column 17. Round this value to three decimal places.  

```{r}


```

# 4. Plotting in "Base R"

```{r}
# Get some data and plot it
plot(sin(seq(-pi,pi,.01))) #plot the sin of every value in the sequence between -pi and pi

# Plot 1 to 10
plot(seq(1,10,1))

# Plot that as a line
plot(seq(1,10,1), type='l')

# Plot that as a blue line
plot(seq(1,10,1), type='l', col = "blue")

# We can plot 2 graphs on the same plot

# Get some data 
x <- seq(-pi,pi,.01)

# Create one plot
plot(sin(x))

# Keep the plot open to overlay something else
par(new=TRUE)

# Plot another graph in a different color so we can easily see the two different graphs
plot(cos(x), col="green")

# Here's another way to do it
lines(tan(x),col="blue") #puts things in same plot, but doesn't overlay

# Get a different x
x <- rnorm(100, mean=100, sd=15) #100 values from normal dist. w/ mean=100, SD=15
#can check mean and sd of our sample
mean(x)
sd(x)
#pretty close to the parameters we set because the sample size is large 
#probably wouldn't be as close if sample size was 5

# Get a histogram of x
hist(x)

# Can do fancier stuff
hist(x, breaks=20) # histogram of x with 20 bins
hist(x, breaks=20, xlab="IQs", main="Histogram of IQs") #title and axes

# Line graphs
x <- seq(-3,3,.01)
y <- seq(1,7,.01)

# Can give values for the x and y axis
plot(x,y)

# Can do fancier stuff here as well
plot(x, y, type = 'l', col = "purple", xlab = "X Axis", ylab = "Y Axis", main = "Graph of X and Y")

# Now let's look at bar plots - get some categorical data
x <- c(10,8,7,7,5)
barplot(x,main="Some RTs", xlab="Group")

# Label the bars
barplot(x, main="Some RTs", xlab="Group", names.arg=c("One", "Two", "Three", "Four", "Five"))

# Add some color
barplot(x,main="Some RTs", xlab="Group", names.arg=c("One", "Two", "Three", "Four", "Five"), col=rainbow(5))

# Which arguments did we use?
?barplot

# Add a legend (probably don't really need this here since bars are labeled...)
legend("topright", c("One", "Two", "Three", "Four", "Five"), cex=0.6, bty="n", fill=rainbow(5))

# What do these arguments mean
?legend

```

# For simple plotting in Base R, I really like this website: https://www.harding.edu/fmccown/r/

(below are some examples borrowed from this website)

This site is nice, too, for understanding graphical parameters: https://www.statmethods.net/advgraphs/parameters.html

```{r}
# Compare cars and trucks
cars <- c(1,3,6,4,9)
trucks <- c(2,5,4,5,12)

# Make a graph for cars. using points connected by a line, y axis ranges from 0 to 12.
plot(cars, type='o', col="blue", ylim=c(0,12), ann=FALSE) 

#ann=FALSE means that R shouldn't label the axes, asking it not to automatically label the y axis right now because it would just be labeled cars and we want to plot trucks, too.

# Graph trucks on the same plot w/ a red dashed line and square points
lines(trucks, type='o', pch=22, lty=2, col="red")

# Add a title & labels for axes
title(main="Autos",col.main="red",font.main=4, xlab="Count", ylab="Total")

```

> **Exercise 4a.** Let's create a graph comparing number of yoga classes taken in a week and stress level. 

Create a variable called `yoga` containing the numbers 0, 1, 2, 3, 4, 5, 6, 7. 

Create a second variable called `stress` containing the numbers 10, 8, 7, 4, 3, 2, 3, 8.  

Create a plot with `yoga` on the x axis and `stress` on the y axis.   

Make sure this is a line graph and make your line blue and dashed. 

Label the x axis `Number of Yoga Classes`.

Label the y axis `Stress Level`. Make sure the y axis ranges from 0 to 10.

Title the graph `Relationship between Yoga and Stress`.

What is the relationship between yoga and stress?
```{r}



```

# 5. Reading data into R

First, you'll need to tell R where to look for the data. To do this, you will set your working directory. 

For this tutorial, your working directory should be wherever you downloaded the materials. (They should be on your desktop.)

```{r}

# What is my current working directory?
getwd()

# How can I change my working directory?
setwd("/Users/jessicakosie/Desktop/uoregon_r_bootcamp/")
getwd()

# What is in my working directory?
dir()

```

You can also do this using RStudio, via the graphical interface on the top:

Session > Set Working Directory > Choose Directory

You can choose the folder you want to work in. The code for setting the working directory will populate in the console. You can then copy/paste this into your code if you'd like.

```{r}
# Now, let's read in the pragmatic_scales_data CSV file and save it as an object called ps_data
ps_data <- read.csv("pragmatic_scales_data.csv", header = TRUE)

```

> ProTip: You can also read in data files generated by other programs like SPSS. There are often packages to help with this.

Here's how you could read in this file if it were an SPSS file. (The code below won't work because the file is a .csv)
```{r}
# Uncomment the line below to install the `foreign` package
# install.packages("foreign")
library(foreign)
ps_data_spss <- read.spss('pragmatic_scales_data.sav', to.data.frame = TRUE)

```

# Examining the data file

You should now see the dataset in your environment.

We can simply look at the data frame. We can also get a summary of the data. (these are all **functions** too!)

```{r}
# Look at the first few rows of the data.
head(ps_data)

# Look at the final few rows of the data.
tail(ps_data)

# You can also specify the number of rows you'd like to see
head(ps_data, n = 10)
tail(ps_data, n = 2)

# Get a summary of the data.
summary(ps_data)

# You can also `View` data, which shows an interactive "spreadsheet" view. You can also get this by clicking on the dataset in the environment.
View(ps_data)

# Note the capital `V`
view(ps_data) #this doesn't work!

# We can also look at the structure of the data.
str(ps_data)

# I can get the column names of the data.
colnames(ps_data)

```

> **Exercise 5a.** Move the file called `another_data_set.csv` from the `uoregon_r_bootcamp` folder on your desktop to a different folder on your computer. Re-set your working directory to that folder. Use `getwd()` to make sure you have the right directory. Read in this new dataset and name it anything you'd like. Use head/tail/summary/etc to check out this data set.

Once you've read in that data file, reset your working directory to the `uoregon_r_bootcamp` folder on your desktop.
```{r}


```
# 6. Indexing and modifying a data frame.

You can select entries in the data frame just like indexing a vector. [row, column]

```{r}
# Get the entire `condition` column.
ps_data[,5]
ps_data[,"condition"]

# Get the entry in row 3, column 4.
ps_data[3, 4]

# Get the entry in row 4 of the item column
ps_data[4, "item"] 
```

> ProTip: Many people use this kind of selection to modify individual entries, like if you just want to correct a single mistake at a paticular point in the data frame. Be careful if you do this, as there will be nothing in the code that tells you that `4` is the *right* element to fix, you'll just have to trust that you got that number right. 
```{r}
# For example:
ps_data[4, "item"] <- "faces"

# Now that entry is changed to "faces"

# Change it back:
ps_data[4, "item"] <- "beds"

# You can do this with column names, too. Maybe I want to change the name of the `item` column to `image`.
colnames(ps_data)[2] <- "image"
colnames(ps_data)
head(ps_data)

# Change it back:
colnames(ps_data)[2] <- "item"

# You can also select an entire column using the $ operation.
ps_data$condition

# ...or ask for only the unique entries from that column
unique(ps_data$condition)

# ...or get the frequency of each unique value
table(ps_data$condition)

# You can also use `table` with multiple variables
table(ps_data$condition, ps_data$item)

# Create a new column from a current column(s).
ps_data$new <- ps_data$age + ps_data$correct
head(ps_data)

# Adding age and correct doesn't make sense. Let's delete that column.
ps_data$new <- NULL
head(ps_data)

```

We can apply functions to an entire column. For example, I can get the mean age for my entire sample.

Note that I have to include the data file in this argument, if I just say mean(age) I'll get an error.

```{r}
mean(age) # doesn't work! I don't  have anything in my environment called "age"

mean(ps_data$age)
```

> **Exercise 6a.** Let's center age. Create a new column called age_centered in which you center age by subtracting the mean age from the age column.

```{r}


```

# Using the `tidyverse`

Content adapted from: https://github.com/mcfrank/tidyverse-tutorial

  > tidyverse is a package that has to be installed and loaded before you can use any of its functions.
  
The functions we've been using so far have been in **base R** and don't require additional packages. To use the functions in the tidyverse packages the `tidyverse` package must first be installed and loaded. Tidyverse packages include tidyr, dplyr, ggplot2, and more - see here for more info: www.tidyverse.org.
  
If you haven't installed the package, you'll need to run this command once:

`install.packages("tidyverse")`

```{r}
# Load the package (tell R that you want to use its functions)
library("tidyverse")
```

We're going to reread the data now, using `read_csv`, which is the `tidyverse` version and works faster and better in a number of ways!

```{r}
ps_data <- read_csv("pragmatic_scales_data.csv")
```


# 7. Pipes

Pipes are a way to write strings of functions more easily. They bring the first argument of the function to the beginning. So you can write:

```{r}
mean(ps_data$age)

# becomes...

ps_data$age %>% mean()
```

That's not very useful yet, but when you start **nesting** functions, it gets better. 

```{r}
mean(unique(ps_data$age))
ps_data$age %>% unique() %>% mean()
ps_data$age %>% unique %>% mean
```

or 

```{r}
round(mean(unique(ps_data$age)), 
      digits = 2)

ps_data$age %>% unique %>% mean %>% round(digits = 2)

# indenting makes things even easier to read
ps_data$age %>%
  unique %>% 
  mean %>% 
  round(digits = 2)
```

This can be super helpful for writing strings of functions so that they are readable and distinct. 

> **Exercise 7a.** Rewrite these commands using pipes and check that they do the same thing! (Or at least produce the same output). 

Unpiped version: length(unique(ps_data$item))

```{r}



```
# 8. Quick Intro to Tidyverse

Using `tidyverse` to explore and characterize the dataset

We are going to manipulate these data using "verbs" from `dplyr`. Here are four verbs that are common in many workflows (but there are many other useful ones):

+ `filter` - remove rows by some logical condition
+ `mutate` - create new columns 
+ `group_by` - group the data into subsets by some column
+ `summarise` - apply some function over columns in each group  

Inspect the various variables before you start any analysis. Earlier we used `summary` but it's not always very useful. 

```{r}
summary(ps_data)
```

This output just feels overwhelming and uninformative. 

You can look at each variable by itself:

```{r}
unique(ps_data$item)

ps_data$subid %>%
 unique 
```

Or use interactive tools like `View` or `DT::datatable` (which I really like).

```{r}
# this won't work unless you first do
# install.packages("DT")
DT::datatable(ps_data) 
```

> ProTip: What we're working with is called "tidy data" where each column is one measure, and each row is one observation. This is, by consensus, the best way to work with tabular data in R. It's actually where the name of `tidyverse` comes from. Check out [this paper](https://www.jstatsoft.org/article/view/v059i10) to learn more. BUT - if you normally work with "wide data", where each row is a subject and different trials are different columns (like what SPSS often does), you can get your data "tidy" using a package called `tidyr`, which is also part of the tidyverse. It's a little tricky so we're not teaching it today, but the verbs that it provides are `gather` and `spread`. 

## Filtering & Mutating

There are lots of reasons you might want to remove *rows* from your dataset, including getting rid of outliers, selecting subpopulations, etc. `filter` is a verb (function) that takes a data frame as its first argument, and then as its second takes the **condition** you want to filter on. 

So if you wanted to look only at 2 and 3 year olds.

```{r}
ps_data %>%
  filter(age > 2, age < 3)

# filter(ps_data, age > 2 & age < 3)

```

Note that we're going to be using pipes with functions over data frames here. The way this works is that:

+ `dplyr` verbs always take the data frame as their first argument, and
+ because pipes pull out the first argument, the data frame just gets passed through successive operations
+ so you can read a pipe chain as "take this data frame and first do this, then do this, then do that."

This is essentially the huge insight of `dplyr`: you can chain verbs into readable and efficient sequences of operations over dataframes, provided 1) the verbs all have the same syntax (which they do) and 2) the data all have the same structure (which they do if they are tidy). 

OK, so filtering:

```{r}
ps_data %>%
  filter(age > 2, 
         age < 3)

```

**Exercise.** Create a smaller datast with **only** the "faces" items in the "Label" condition.

```{r}


```

> ProTip: You can think about `filter`ing as similar to "logical indexing", where you use a vector of `TRUE` and `FALSE`s to get a part of a dataset, for example, `ps_data[ps_data$items == "faces",]`. This command creates a logical vector `ps_data$items == "faces"` and uses it as a condition for filtering.

There are also times when you want to add or remove *columns*. You might want to remove columns to simplify the dataset. If you wanted to do that, the verb is `select`. 

```{r}
ps_data %>%
  select(subid, age, correct) 

ps_data %>%
  select(-condition) 

ps_data %>%
  select(1) 

ps_data %>%
  select(starts_with("co")) 

# learn about this with ?select
```

Perhaps more useful is *adding columns*. You might do this perhaps to compute some kind of derived variable. `mutate` is the verb for these situations - it allows you to add a column. Let's add a discrete age group factor to our dataset.

```{r}
ps_data <- ps_data %>%
  mutate(age_group = cut(age, 2:5, include.lowest = TRUE), 
         age_centered = age - mean(age))

head(ps_data)

```


## Standard psychological descriptives

We typically describe datasets at the level of subjects, not trials. We need two verbs to get a summary at the level of subjects: `group_by` and `summarise` (kiwi spelling). Grouping alone doesn't do much.

```{r}
ps_data %>%
  group_by(age_group) 
```

All it does is add a grouping marker. 

What `summarise` does is to *apply a function* to a part of the dataset to create a new summary dataset. So we can apply the function `mean` to the dataset and get the grand mean. 

```{r}
## DO NOT DO THIS!!!
# foo <- initialize_the_thing_being_bound()
# for (i in 1:length(unique(ps_data$item))) {
#   for (j in 1:length(unique(ps_data$condition))) {
#     this_data <- ps_data[ps_data$item == unique(ps_data$item)[i] & 
#                       ps_data$condition == unique(ps_data$condition)[n],]
#     do_a_thing(this_data)
#     bind_together_somehow(this_data)
#   }
# }

ps_data %>%
  summarise(correct = mean(correct))
```

Note the syntax here: `summarise` takes multiple  `new_column_name = function_to_be_applied_to_data(data_column)` entries in a list. Using this syntax, we can create more elaborate summary datasets also:

```{r}
ps_data %>%
  summarise(correct = mean(correct), 
            n_observations = length(subid))
```

Where these two verbs shine is in combination, though. Because `summarise` applies functions to columns in your *grouped data*, not just to the whole dataset!

So we can group by age or condition or whatever else we want and then carry out the same procedure, and all of a sudden we are doing something extremely useful!

```{r}
ps_means_nosubgrouping <- ps_data %>%
  group_by(age_group, condition) %>%
  summarise(correct_mean = mean(correct),
            correct_sd = sd(correct),
            n_observations = length(subid))
ps_means_nosubgrouping
```

> **Exercise.** One of the most important analytic workflows for psychological data is to take some function (e.g., the mean) *for each participant* and then look at grand means and variability *across participant means*. This analytic workflow requires grouping, summarising, and then grouping again and summarising again! Use `dplyr` to make the same table as above (`ps_means`) but with means computed across subject means, not across all data points. Then, take that data and get means for age_group and condition. (The means will be pretty similar as this is a balanced design but in a case with lots of missing data, they will vary.) 

```{r}


```

## Playing around with SWIRL

```{r}

# I highly recommend trying out the swirl package!

install.packages("swirl") # give it time to install, if you're using R Studio you'll see a little 
# stop sign in the top right corner of the console until it's finished installing.
library(swirl)
swirl()  # have fun! :)

```
